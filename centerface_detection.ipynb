{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08abf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from typing import List, Tuple, Union\n",
    "import logging\n",
    "import tensorrt as trt\n",
    "import sys\n",
    "\n",
    "def remove_initializer_from_input(input, output):\n",
    "\n",
    "    model = onnx.load(input)\n",
    "    if model.ir_version < 4:\n",
    "        print(\n",
    "            'Model with ir_version below 4 requires to include initilizer in graph input'\n",
    "        )\n",
    "        return\n",
    "\n",
    "    inputs = model.graph.input\n",
    "    name_to_input = {}\n",
    "    for input in inputs:\n",
    "        name_to_input[input.name] = input\n",
    "\n",
    "    for initializer in model.graph.initializer:\n",
    "        if initializer.name in name_to_input:\n",
    "            inputs.remove(name_to_input[initializer.name])\n",
    "\n",
    "    onnx.save(model, output)\n",
    "    \n",
    "\n",
    "def reshape(model):\n",
    "    \n",
    "    # New width and height. Using -1,-1 so that we can use variable input size in model while using triton inference server.\n",
    "    value = -1 \n",
    "    inputs = model.graph.input\n",
    "    outputs = model.graph.output\n",
    "\n",
    "    inputs[0].type.tensor_type.shape.dim[0].dim_value = -1\n",
    "    inputs[0].type.tensor_type.shape.dim[2].dim_value = value\n",
    "    inputs[0].type.tensor_type.shape.dim[3].dim_value = value\n",
    "    \n",
    "    for output in outputs:\n",
    "        output.type.tensor_type.shape.dim[0].dim_value = -1\n",
    "        output.type.tensor_type.shape.dim[2].dim_value = value # \n",
    "        output.type.tensor_type.shape.dim[3].dim_value = value\n",
    "    return model\n",
    "\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "\n",
    "def _build_engine_onnx(input_onnx: Union[str, bytes], force_fp16: bool = False, max_batch_size: int = 1,\n",
    "                       max_workspace: int = 1024):\n",
    "\n",
    "    with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "            builder.create_network(EXPLICIT_BATCH) as network, \\\n",
    "            builder.create_builder_config() as config, \\\n",
    "            trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        has_fp16 = builder.platform_has_fast_fp16\n",
    "        if force_fp16 or has_fp16:\n",
    "            logging.info('Building TensorRT engine with FP16 support.')\n",
    "            if not has_fp16:\n",
    "                logging.warning('Builder reports no fast FP16 support. Performance drop expected.')\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "        else:\n",
    "            logging.warning('Building engine in FP32 mode.')\n",
    "\n",
    "        config.max_workspace_size = max_workspace * 1024 * 1024\n",
    "\n",
    "        if not parser.parse(input_onnx):\n",
    "            print('ERROR: Failed to parse the ONNX')\n",
    "            for error in range(parser.num_errors):\n",
    "                print(parser.get_error(error))\n",
    "            sys.exit(1)\n",
    "\n",
    "        if max_batch_size != 1:\n",
    "            logging.warning('Batch size !=1 is used. Ensure your inference code supports it.')\n",
    "        profile = builder.create_optimization_profile()\n",
    "        # Get input name and shape for building optimization profile\n",
    "        input = network.get_input(0)\n",
    "        inp_shape = list(input.shape)\n",
    "        inp_shape[0] = 1\n",
    "        min_opt_shape = tuple(inp_shape)\n",
    "        inp_shape[0] = max_batch_size\n",
    "        max_shape = tuple(inp_shape)\n",
    "        input_name = input.name\n",
    "        profile.set_shape(input_name, min_opt_shape, min_opt_shape, max_shape)\n",
    "        config.add_optimization_profile(profile)\n",
    "\n",
    "        return builder.build_engine(network, config=config)\n",
    "\n",
    "\n",
    "def check_fp16():\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    has_fp16 = builder.platform_has_fast_fp16\n",
    "    return has_fp16\n",
    "\n",
    "\n",
    "def convert_onnx(input_onnx: Union[str, bytes], engine_file_path: str, force_fp16: bool = False,\n",
    "                 max_batch_size: int = 1):\n",
    "    '''\n",
    "    Creates TensorRT engine and serializes it to disk\n",
    "    :param input_onnx: Path to ONNX file on disk or serialized ONNX model.\n",
    "    :param engine_file_path: Path where TensorRT engine should be saved.\n",
    "    :param force_fp16: Force use of FP16 precision, even if device doesn't support it. Be careful.\n",
    "    :param max_batch_size: Define maximum batch size supported by engine. If >1 creates optimization profile.\n",
    "    :return: None\n",
    "    '''\n",
    "\n",
    "    onnx_obj = None\n",
    "    if isinstance(input_onnx, str):\n",
    "        with open(input_onnx, \"rb\") as f:\n",
    "            onnx_obj = f.read()\n",
    "    elif isinstance(input_onnx, bytes):\n",
    "        onnx_obj = input_onnx\n",
    "\n",
    "    engine = _build_engine_onnx(input_onnx=onnx_obj,\n",
    "                                force_fp16=force_fp16, max_batch_size=max_batch_size)\n",
    "\n",
    "    assert not isinstance(engine, type(None))\n",
    "\n",
    "    with open(engine_file_path, \"wb\") as f:\n",
    "        f.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a607b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_initializer_from_input('centerface.onnx', 'centerface_clean.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611818f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"input.1\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 3\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 32\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[name: \"537\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"538\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"539\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"540\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "net1 = onnx.load('centerface.onnx')\n",
    "print((net1.graph.input)[0])\n",
    "print((net1.graph.output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b09ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"input.1\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 3\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 32\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 32\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[name: \"537\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"538\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"539\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"540\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 8\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "net2 = onnx.load('centerface_clean.onnx')\n",
    "print((net2.graph.input)[0])\n",
    "print((net2.graph.output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797e7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = [640, 480]\n",
    "max_batch_size = 128\n",
    "if max_batch_size !=1:\n",
    "    batch_size=-1\n",
    "\n",
    "model = onnx.load('centerface.onnx')\n",
    "reshaped = reshape(model)\n",
    "onnx.save(reshaped, 'centerface_dynamic2.onnx')\n",
    "# with open('centerface_dynamic.onnx', \"wb\") as file_handle:\n",
    "#     serialized = reshaped.SerializeToString()\n",
    "#     file_handle.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec3629c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"input.1\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 3\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[name: \"537\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"538\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"539\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"540\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 10\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: -1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "net3 = onnx.load('centerface_dynamic2.onnx')\n",
    "print((net3.graph.input)[0])\n",
    "print((net3.graph.output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd99525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch size !=1 is used. Ensure your inference code supports it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/05/2023-19:31:43] [TRT] [E] 3: [optimizationProfile.cpp::setDimensions::128] Error Code 3: API Usage Error (Parameter check failed at: runtime/common/optimizationProfile.cpp::setDimensions::128, condition: std::all_of(dims.d, dims.d + dims.nbDims, [](int32_t x) noexcept { return x >= 0; })\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Shape provided for min is inconsistent with other shapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconvert_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mengine_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcenterface_dynamic2.plan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[43mforce_fp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mconvert_onnx\u001b[0;34m(input_onnx, engine_file_path, force_fp16, max_batch_size)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_onnx, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    116\u001b[0m     onnx_obj \u001b[38;5;241m=\u001b[39m input_onnx\n\u001b[0;32m--> 118\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43m_build_engine_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_onnx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monnx_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mforce_fp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_fp16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(engine, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(engine_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m_build_engine_onnx\u001b[0;34m(input_onnx, force_fp16, max_batch_size, max_workspace)\u001b[0m\n\u001b[1;32m     86\u001b[0m max_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(inp_shape)\n\u001b[1;32m     87\u001b[0m input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m---> 88\u001b[0m \u001b[43mprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_opt_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_opt_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m config\u001b[38;5;241m.\u001b[39madd_optimization_profile(profile)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mbuild_engine(network, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Shape provided for min is inconsistent with other shapes."
     ]
    }
   ],
   "source": [
    "convert_onnx(serialized, \n",
    "             engine_file_path='centerface_dynamic.plan',\n",
    "             max_batch_size=max_batch_size,\n",
    "             force_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b993a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
